{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-index in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (0.7.9)\n",
      "Collecting llama_hub\n",
      "  Obtaining dependency information for llama_hub from https://files.pythonhosted.org/packages/5d/6d/3d23de219fec9394e4f96a6310df32ff1921ca79e83bfcf51e99875be23a/llama_hub-0.0.15-py3-none-any.whl.metadata\n",
      "  Downloading llama_hub-0.0.15-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tiktoken in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.5.7)\n",
      "Requirement already satisfied: langchain>=0.0.218 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.0.235)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (2.0.15)\n",
      "Requirement already satisfied: numpy in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (8.2.2)\n",
      "Requirement already satisfied: openai>=0.26.4 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.27.7)\n",
      "Requirement already satisfied: pandas in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.5.3)\n",
      "Requirement already satisfied: urllib3<2 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.26.16)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (2023.5.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (4.6.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (4.12.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama-index) (1.5.6)\n",
      "Collecting atlassian-python-api (from llama_hub)\n",
      "  Downloading atlassian-python-api-3.40.0.tar.gz (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.8/157.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting html2text (from llama_hub)\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: psutil in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from llama_hub) (5.9.5)\n",
      "Collecting retrying (from llama_hub)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.0.8,>=0.0.7 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (0.0.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from langchain>=0.0.218->llama-index) (1.10.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from dataclasses-json->llama-index) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.5.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
      "Requirement already satisfied: deprecated in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from atlassian-python-api->llama_hub) (1.2.14)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from atlassian-python-api->llama_hub) (1.15.0)\n",
      "Requirement already satisfied: oauthlib in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from atlassian-python-api->llama_hub) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from atlassian-python-api->llama_hub) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->llama-index) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from pandas->llama-index) (2023.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from tiktoken->llama-index) (2023.5.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/derekdeming/Library/Python/3.9/lib/python/site-packages (from deprecated->atlassian-python-api->llama_hub) (1.14.1)\n",
      "Downloading llama_hub-0.0.15-py3-none-any.whl (887 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.0/887.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: wikipedia, atlassian-python-api\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=48f9cfdf31af9ba0e1a9f1964005e2e6709c02ebc83d3bca6f93804c1fe19c13\n",
      "  Stored in directory: /Users/derekdeming/Library/Caches/pip/wheels/c2/46/f4/caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "  Building wheel for atlassian-python-api (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for atlassian-python-api: filename=atlassian_python_api-3.40.0-py3-none-any.whl size=163813 sha256=334b929c9568e4aa9cff3a249b1fdde34c53a07d4f5c5b1bc2c95d7a2fc8cc56\n",
      "  Stored in directory: /Users/derekdeming/Library/Caches/pip/wheels/0d/59/6a/618f53bb3c7fc046fcdb1009cd9c38db4aeeb73d0bc2fa46cf\n",
      "Successfully built wikipedia atlassian-python-api\n",
      "Installing collected packages: retrying, html2text, wikipedia, atlassian-python-api, llama_hub\n",
      "Successfully installed atlassian-python-api-3.40.0 html2text-2020.1.16 llama_hub-0.0.15 retrying-1.3.4 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index llama_hub wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from IPython import display \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LlamaHub connectors and basic queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_hub.wikipedia.base import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "documents = loader.load_data(pages=['BioRxiv', 'Bioinformatics', 'Cheminformatics', 'Large language model', 'Transformer (machine learning model)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='37f8f88a-5d43-4dc5-899b-40a1a58f7e91', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='a7402335edcbbb5760d816f26ec37a84ee5426c441aed2924c046b4546289608', text='bioRxiv (pronounced \"bio-archive\") is an open access preprint repository for the biological sciences co-founded by John Inglis and Richard Sever in November 2013. It is hosted by the Cold Spring Harbor Laboratory (CSHL).As preprints, papers hosted on bioRxiv are not peer-reviewed, but undergo basic screening and checked against plagiarism. However, peer reviews from other sources may be posted alongside preprints. Moreover, readers may post comments. \\nIt has been measured that two thirds of the papers posted in bioRxiv are later published in peer-reviewed journals. BioRxiv, and its sister site, medRxiv, have been major sources for the dissemination of COVID-19 research.\\n\\n\\n== History ==\\nBioRxiv was inspired by and intends to complement the arXiv repository, which mostly focuses on mathematics, physics and connected disciplines, launched in 1991 by Paul Ginsparg (who also serves on the bioRxiv advisory board). It received support from both the CSHL and the Lourie Foundation. Additional funding from the Chan Zuckerberg Initiative was confirmed in April 2017.Prior to the establishment of bioRxiv, biological scientists were divided on the issue of having a dedicated preprint open-access repository. Many had concerns of having their research scooped by competitors and losing their claim to discovery. However, several geneticists had submitted papers to the \"quantitative biology\" section of the arXiv repository (launched in 2003) and no longer had those concerns, as they could point to preprints to support their claims of discovery.\\n\\n\\n== Submission rate ==\\nJocelyn Kaiser of Science said that in its first year, the repository had \"attracted a modest but growing stream of papers\", having hosted 824 preprints. \\nOver 20,000 tweets were made about bioRxiv-hosted preprints in 2015.As of February 2016, the submission rate to bioRxiv had steadily increased from ≈60 to ≈200 per month. In 2017, the number of monthly submissions rose from over 800 in March to more than 1000 in July with a total number of 10,722 papers submitted in 2017.In the year of 2018, a total of 20,000 manuscripts were submitted, which results in a monthly average of 1600 papers.In the year 2019, over 31,000 manuscripts were submitted, which results in a monthly average of 2600 papers (which accelerated to just over 3000 papers per month in the last quarter of 2019).The number of yearly manuscripts rose to 38,088 in 2020, then slightly increased to 40,223 in 2021, followed by 36,417 manuscripts being published in 2022. As of December 31, 2022, almost 180,000 preprints have been accepted in total.\\n\\n\\n== Fields ==\\nbioRxiv accepts preprints in the following disciplines\\n\\n\\n== bioRxiv, journals, and open peer review ==\\nAs a result of bioRxiv\\'s popularity, many biology journals have updated their policies on preprints, clarifying they do not consider preprints to be a \\'prior publication\\' for purpose of the Ingelfinger rule. \\nThe bioRxiv to Journals (B2J) initiative allows authors to submit their manuscript directly to a journal\\'s submission system through bioRxiv. As of May 2020, 177 journals participate in the initiative.In 2019, BioRxiv started allowing posting reviews alongside preprints, in addition to allowing comments on preprints. The reviews can come from journals or from platforms such as Review Commons.\\n\\n\\n== See also ==\\nList of preprint repositories\\nArXiv\\nChemRxiv\\nMedRxiv\\nPeerJ Preprints\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nJansen, Jaclyn (12 November 2013). \"CSHL launches bioRxiv, a freely accessible, citable preprint server for biology\". Cold Spring Harbor Laboratory. Archived from the original on 20 December 2016. Retrieved 11 September 2016.\\nKaiser, Jocelyn (12 November 2013). \"New Preprint Server Aims to Be Biologists\\' Answer to Physicists\\' arXiv\". Science. Retrieved 2016-10-30.\\n\"BioRxiv preprint server launched\". UC Berkeley Library News. 15 November 2013. Retrieved 2016-09-11.\\nCallaway, Ewen; Powell, Kendall (16 February 2016). \"Biologists urged to hug a preprint\". Nature. 530 (7590): 265. Bibcode:2016Natur.530..265C. doi:10.1038/530265a. PMID 26887471.\\nInglis, John (22 September 2016). \"The bioRxiv preprint service\" (PDF). COASP 2016.\\n\\n\\n== External links ==\\n\\nOfficial website', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "# build an index over these Document objects.\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# we can now query an index with the default QueryEngine\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"what is the purpose of bioinformaticians\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='\\nThe purpose of bioinformaticians is to develop and implement computer programs to efficiently access, manage, and use various types of biological data, develop new mathematical algorithms and statistical measures to assess relationships among members of large data sets, and analyze and interpret biological data in order to increase the understanding of biological processes.', source_nodes=[NodeWithScore(node=TextNode(id_='45269cca-30a2-4aa4-8cb6-9b59a1296153', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f76e119-1f2c-4929-9dcd-538bc82b0334', node_type=None, metadata={}, hash='31e10b333619c21367b04caeb895873fed59d65e9f88f27d8d42de39a92e04b4'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b77aa9f6-792d-4a01-875c-b46f255de200', node_type=None, metadata={}, hash='3800b13fbceab0cb9e829522e1743f4ee6343094d93de1e6526bc7b278f08180')}, hash='91f4eb50df9ae2fb135fe635b85b65e193cb0338ac73cd006983a6c82af3684f', text='Bioinformatics ( (listen)) is an interdisciplinary field of science that develops methods and software tools for understanding biological data, especially when the data sets are large and complex. Bioinformatics uses biology, chemistry, physics, computer science, computer programming, information engineering, mathematics and statistics to analyze and interpret biological data. The subsequent process of analyzing and interpreting data is referred to as computational biology. \\nComputational, statistical, and computer programming techniques have been used  for computer simulation analyses of biological queries. They include reused specific analysis \"pipelines\", particularly in the field of genomics, such as by the identification of genes and single nucleotide polymorphisms (SNPs). These pipelines are used to better understand the genetic basis of disease, unique adaptations, desirable properties (esp. in agricultural species), or differences between populations. Bioinformatics also includes proteomics, which tries to understand the organizational principles within nucleic acid and protein sequences.Image and signal processing allow extraction of useful results from large amounts of raw data. In the field of genetics, it aids in sequencing and annotating genomes and their observed mutations. Bioinformatics includes text mining of biological literature and the development of biological and gene ontologies to organize and query biological data. It also plays a role in the analysis of gene and protein expression and regulation. Bioinformatics tools aid in comparing, analyzing and interpreting genetic and genomic data and more generally in the understanding of evolutionary aspects of molecular biology. At a more integrative level, it helps analyze and catalogue the biological pathways and networks that are an important part of systems biology. In structural biology, it aids in the simulation and modeling of DNA, RNA, proteins as well as biomolecular interactions.\\n\\n\\n== History ==\\nThe first definition of the term bioinformatics was coined by Paulien Hogeweg and Ben Hesper in 1970, to refer to the study of information processes in biotic systems. This definition placed bioinformatics as a field parallel to biochemistry (the study of chemical processes in biological systems).Bioinformatics and computational biology involved the analysis of biological data, particularly DNA, RNA, and protein sequences. The field of bioinformatics experienced explosive growth starting in the mid-1990s, driven largely by the Human Genome Project and by rapid advances in DNA sequencing technology.\\nAnalyzing biological data to produce meaningful information involves writing and running software programs that use algorithms from graph theory, artificial intelligence, soft computing, data mining, image processing, and computer simulation. The algorithms in turn depend on theoretical foundations such as discrete mathematics, control theory, system theory, information theory, and statistics.\\n\\n\\n=== Sequences ===\\nThere has been a tremendous advance in speed and cost reduction since the completion of the Human Genome Project, with some labs able to sequence over 100,000 billion bases each year, and a full genome can be sequenced for $1,000 or less.Computers became essential in molecular biology when protein sequences became available after Frederick Sanger determined the sequence of insulin in the early 1950s. Comparing multiple sequences manually turned out to be impractical. Margaret Oakley Dayhoff, a pioneer in the field, compiled one of the first protein sequence databases, initially published as books as well as methods of sequence alignment and molecular evolution. Another early contributor to bioinformatics was Elvin A. Kabat, who pioneered biological sequence analysis in 1970 with his comprehensive volumes of antibody sequences released online with Tai Te Wu between 1980 and 1991.In the 1970s, new techniques for sequencing DNA were applied to bacteriophage MS2 and øX174, and the extended nucleotide sequences were then parsed with informational and statistical algorithms.  These studies illustrated that well known features, such as the coding segments and the triplet code, are revealed in straightforward statistical analyses and were the proof of the concept that bioinformatics would be insightful.\\n\\n\\n== Goals ==\\nIn order to study', start_char_idx=0, end_char_idx=4377, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8626769054169309), NodeWithScore(node=TextNode(id_='b77aa9f6-792d-4a01-875c-b46f255de200', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f76e119-1f2c-4929-9dcd-538bc82b0334', node_type=None, metadata={}, hash='31e10b333619c21367b04caeb895873fed59d65e9f88f27d8d42de39a92e04b4'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='45269cca-30a2-4aa4-8cb6-9b59a1296153', node_type=None, metadata={}, hash='91f4eb50df9ae2fb135fe635b85b65e193cb0338ac73cd006983a6c82af3684f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd5586b1-8909-48c0-9dc4-2c35ec899325', node_type=None, metadata={}, hash='b5fdcef4623ad9062be68ba82878c00617c3a5b13bb2161ff509ff5b0b8128fe')}, hash='3800b13fbceab0cb9e829522e1743f4ee6343094d93de1e6526bc7b278f08180', text='would be insightful.\\n\\n\\n== Goals ==\\nIn order to study how normal cellular activities are altered in different disease states, raw biological data must be combined to form a comprehensive picture of these activities. Therefore, the field of bioinformatics has evolved such that the most pressing task now involves the analysis and interpretation of various types of data. This also includes nucleotide and amino acid sequences, protein domains, and protein structures.Important sub-disciplines within bioinformatics and computational biology include:\\n\\nDevelopment and implementation of computer programs to efficiently access, manage, and use various types of information.\\nDevelopment of new mathematical algorithms and statistical measures to assess relationships among members of large data sets. For example, there are methods to locate a gene within a sequence, to predict protein structure and/or function, and to cluster protein sequences into families of related sequences.The primary goal of bioinformatics is to increase the understanding of biological processes. What sets it apart from other approaches is its focus on developing and applying computationally intensive techniques to achieve this goal. Examples include: pattern recognition, data mining, machine learning algorithms, and visualization. Major research efforts in the field include sequence alignment, gene finding, genome assembly, drug design, drug discovery, protein structure alignment, protein structure prediction, prediction of gene expression and protein–protein interactions, genome-wide association studies, the modeling of evolution and cell division/mitosis.\\nBioinformatics entails the creation and advancement of databases, algorithms, computational and statistical techniques, and theory to solve formal and practical problems arising from the management and analysis of biological data.\\nOver the past few decades, rapid developments in genomic and other molecular research technologies and developments in information technologies have combined to produce a tremendous amount of information related to molecular biology. Bioinformatics is the name given to these mathematical and computing approaches used to glean understanding of biological processes.\\nCommon activities in bioinformatics include mapping and analyzing DNA and protein sequences, aligning DNA and protein sequences to compare them, and creating and viewing 3-D models of protein structures.\\n\\n\\n== Sequence analysis ==\\n\\nSince the bacteriophage Phage Φ-X174 was sequenced in 1977, the DNA sequences of thousands of organisms have been decoded and stored in databases. This sequence information is analyzed to determine genes that encode proteins, RNA genes, regulatory sequences, structural motifs, and repetitive sequences. A comparison of genes within a species or between different species can show similarities between protein functions, or relations between species (the use of molecular systematics to construct phylogenetic trees). With the growing amount of data, it long ago became impractical to analyze DNA sequences manually. Computer programs such as BLAST are used routinely to search sequences—as of 2008, from more than 260,000 organisms, containing over 190 billion nucleotides.\\n\\n\\n=== DNA sequencing ===\\n\\nBefore sequences can be analyzed, they are obtained from a data storage bank, such as GenBank. DNA sequencing is still a non-trivial problem as the raw data may be noisy or affected by weak signals. Algorithms have been developed for base calling for the various experimental approaches to DNA sequencing.\\n\\n\\n=== Sequence assembly ===\\n\\nMost DNA sequencing techniques produce short fragments of sequence that need to be assembled to obtain complete gene or genome sequences. The shotgun sequencing technique (used by The Institute for Genomic Research (TIGR) to sequence the first bacterial genome, Haemophilus influenzae) generates the sequences of many thousands of small DNA fragments (ranging from 35 to 900 nucleotides long, depending on the sequencing technology). The ends of these fragments overlap and, when aligned properly by a genome assembly program, can be used to reconstruct the complete genome. Shotgun sequencing yields sequence data quickly, but the task of assembling the fragments can be quite complicated for larger genomes. For a genome as large as the', start_char_idx=4333, end_char_idx=8680, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8612775521855058)], metadata={'45269cca-30a2-4aa4-8cb6-9b59a1296153': {}, 'b77aa9f6-792d-4a01-875c-b46f255de200': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying over multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, LLMPredictor, ServiceContext, VectorStoreIndex\n",
    "from llama_index.response.pprint_utils import pprint_response\n",
    "from langchain import OpenAI\n",
    "\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekdeming/Library/Python/3.9/lib/python/site-packages/langchain/llms/openai.py:173: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/derekdeming/Library/Python/3.9/lib/python/site-packages/langchain/llms/openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-4\", max_tokens=-1, streaming=True))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
